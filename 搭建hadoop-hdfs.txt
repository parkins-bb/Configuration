https://www.jianshu.com/p/58b39974abb7 教程
https://www.cnblogs.com/yinzhengjie/articles/11063804.html 常见配置
http://dblab.xmu.edu.cn/blog/1177-2/  -- 分布式集群环境搭建
/etc/hosts:
★★★注：将配置的本机ip改为内网IP其它为公网
172.24.60.28 master
47.93.190.182 slave1
47.94.169.129 slave2
39.105.37.10  slave3

查看端口开放 : netstat -ant

★★★首先搭建ssh免密登录

linux：master与slaves配置相同：
-------------------------------------------
安装配置jdk 
$ javac 获取下载源
$ apt-get install openjdk-8-jdk
此时看到java的安装路径：/usr/lib/jvm/java-8-openjdk-amd64/
配置环境变量：vi /etc/profile
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH
使环境变量生效：source /etc/profile
------------------------------------------
安装配置hadoop
$ wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.7.7/hadoop-2.7.7.tar.gz
$ mv hadoop-2.7.7.tar.gz /opt/
$ cd /opt
$ tar -zxvf hadoop-2.7.7.tar.gz

配置hadoop-env.sh:
JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/

配置：vi /etc/profile
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/
export JRE_HOME=$JAVA_HOME/jre
export HADOOP_HOME=/opt/hadoop-2.7.7
export CLASSPATH=$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
生效：source /etc/profile

配置core-site.xml:
mkdir -p /opt/hadoop-2.7.7/data/tmpData
$ cd /opt/hadoop-2.7.7/etc/hadoop
$ vi core-site.xml
★★★注意：master上阿里云这里需要配置为内网IP
<configuration>
 <property>
  <name>fs.defaultFS</name>
  <value>hdfs://172.24.60.11:9000</value> 或者是<value>hdfs://master:9000</value>
 </property>
 <property>
  <name>hadoop.tmp.dir</name>
  <value>/opt/hadoop</value>
 </property>
 <property>
   <name>dfs.name.dir</name>
   <value>/opt/hadoop/name</value>
 </property>
</configuration>

修改hdfs-site.xml

<configuration>
 <property>
   <name>dfs.data.dir</name>
   <value>/opt/hadoop/data</value>
 </property>
 <property>
   <name>dfs.replication</name>
   <value>2</value>
 </property>
</configuration>
---------------------------
以上是Hafoop-hdfs 搭建过程
以下是添加Hadoop-MapReduce搭建过程
--------------------------
修改yarn-site.xml 

<configuration>
<!-- Site specific YARN configuration properties -->
   <property>
      <name>yarn.nodemanager.aux-services</name>
      <value>mapreduce_shuffle</value>
   </property>
   <property>
     <name>yarn.resourcemanager.hostname</name>
      <value>master</value>
   </property>
</configuration>

复制mapred-site.xml.template 为mapred-site.xml
$ cp mapred-site.xml.template mapred-site.xml

修改mapred-site.xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
  </configuration>
  
配置slaves 在NameNode上配置即master:
$ vim slaves
  slave1
  slave2
  slave3

slaves上配置相同
slaves上的变化，将 core-site.xml中
 <property>
  <name>fs.defaultFS</name>
  <value>hdfs://master:9000</value>
 </property>
---------------------------
格式化NameNode、启动HDFS系统：
格式化：
$ hdfs namenode -format
启动：
$ start-dfs.sh
验证启动是否成功：
http://192.168.56.101:50070/

★★★注意：
配置失败重新配置后，需要格式化操作：
格式化之前：
删除logs下面的日志文件 cd /opt/hadoop-2.7.7/logs  rm -rf *  
删除 /opt/hadoop下所有内容（master 和 slaves 
hdfs namenode -format
start-all.sh 启动HDFS和Yarn
start-yarn.sh 启动Hadoop MapReduce框架Yarn
start-dfs.sh 启动HDFS
输入jps看启动是否成功
master上jps：
19360 SecondaryNameNode
19505 ResourceManager
19833 Jps
19163 NameNode
slaves上jps：
866 Application
24930 Jps
24743 NodeManager
24633 DataNode
web查看：
打开Hadoop ResourceManager Web 界面
http://47.94.95.35:8088
打开Hadoop NameNode HDFS Web 界面
http://47.94.95.35:50070:
配置过程中将/etc/hosts下的本机ip改为内网其他公网  
47.94.95.35 master  改为 172.24.60.28 master  
39.105.37.10 slave1  
47.93.36.9 slave2  
182.92.189.62 slave3  




